{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "5cfdf793",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "from scipy.linalg import qr as scipy_qr\n",
    "from scipy.linalg import solve_triangular as scipy_solve_triangular\n",
    "# from scipy.sparse.linalg._interface import MatrixLinearOperator, _CustomLinearOperator\n",
    "import scipy.sparse as sps\n",
    "import scipy.sparse.linalg as splinalg\n",
    "import math\n",
    "\n",
    "from scipy.linalg import null_space\n",
    "\n",
    "# from .matrix import MatrixOperator, SparseMatrixOperator\n",
    "# from .util import banded_cholesky_factorization\n",
    "# from .diagonal import DiagonalOperator\n",
    "# from .derivatives import DiscreteGradientNeumann2D\n",
    "# from .dct import build_dct_Lpinv\n",
    "\n",
    "import cupy as cp\n",
    "\n",
    "from jlinops import MatrixLinearOperator, MatrixLinearOperator, cg, _CustomLinearOperator\n",
    "from jlinops import banded_cholesky\n",
    "from jlinops import issparse, tosparse\n",
    "from jlinops import scipy_superlu_to_cupy_superlu\n",
    "from jlinops import check_adjoint\n",
    "from jlinops import dct_sqrt_pinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b974fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46f91b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.normal(size=(40,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1db0b1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<40x40 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1600 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tosparse(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "969789b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = cp.random.normal(size=(40,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e35b5aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cupyx.scipy.sparse._csc.csc_matrix at 0x7f18be998910>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tosparse(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb5bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a887e37c",
   "metadata": {},
   "source": [
    "# Figure out superlu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be931d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cupyx.scipy.sparse.linalg import SuperLU as cp_SuperLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b2962bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.normal(size=(40,40))\n",
    "A = tosparse(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb479b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse LU\n",
    "LU = splinalg.splu(A, diag_pivot_thresh=0, permc_spec=\"NATURAL\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3be63ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cupyx.scipy.sparse.linalg._solve.SuperLU at 0x7f18b1b875d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_SuperLU(LU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154abc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948961bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4be5bffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BandedCholeskyPinvOperator(_CustomLinearOperator):\n",
    "    \"\"\"Takes a (non-square) MatrixLinearOperator A and builds a linear operator representing an approximation to the \n",
    "    pseudo-inverse of A. This is most efficient if A^T A is sparse and (already) banded.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, A, delta=1e-3, _superlu=None):\n",
    "\n",
    "        assert isinstance(A, MatrixLinearOperator), \"Must give MatrixOperator as an input.\"\n",
    "        \n",
    "        # Bind\n",
    "        self.original_op = A\n",
    "        self.original_shape = A.shape\n",
    "        self.delta = delta\n",
    "        \n",
    "        # Device\n",
    "        device = A.device\n",
    "        \n",
    "        # Original shape\n",
    "        k, n = A.shape\n",
    "        \n",
    "        # Enforce that underling A.T A is a sparse type\n",
    "        if not issparse(A.A):\n",
    "            AtA = MatrixLinearOperator( tosparse(A.A.T @ A.A).tocsc() )\n",
    "        else:\n",
    "            AtA = MatrixLinearOperator(A.A.T @ A.A)\n",
    "        \n",
    "        # Even if on GPU, factorize and make superlu object on CPU\n",
    "        if device == \"cpu\":\n",
    "            AtA_cpu = AtA\n",
    "        else:\n",
    "            AtA_cpu = AtA.to_cpu()\n",
    "            \n",
    "        # Matrix we will factorize\n",
    "        mat = AtA_cpu.A + self.delta*sps.eye(n)\n",
    "        \n",
    "        # Perform factorization\n",
    "        chol_fac, superlu = banded_cholesky( mat )\n",
    "        \n",
    "        # Make GPU superlu object if applicable\n",
    "        if device == \"gpu\":\n",
    "            superlu = cp_SuperLU(superlu)\n",
    "            \n",
    "        # Bind superlu and A\n",
    "        self.superlu = superlu\n",
    "        self.A = A\n",
    "            \n",
    "        # Build matvec and rmatvec\n",
    "        def _matvec(x):\n",
    "            tmp = self.A.rmatvec(x)\n",
    "            tmp = self.superlu.solve(tmp, trans=\"N\")\n",
    "            return tmp\n",
    "        \n",
    "        def _rmatvec(x):\n",
    "            tmp = self.superlu.solve(x, trans=\"T\")\n",
    "            tmp = self.A.matvec(tmp)\n",
    "            return tmp\n",
    "        \n",
    "        super().__init__( (n,k), _matvec, _rmatvec, device=device, dtype=A.dtype)\n",
    "        \n",
    "        \n",
    "    def to_gpu(self):\n",
    "        \n",
    "        # Switch to CPU superlu\n",
    "        superlu = cp_SuperLU(self.superlu)\n",
    "        \n",
    "        return BandedCholeskyPinvOperator(A.to_gpu(), delta=self.delta, _superlu=superlu)\n",
    "    \n",
    "    \n",
    "    def to_cpu(self):\n",
    "        \n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f278661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d07b193",
   "metadata": {},
   "source": [
    "# Test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "10304ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Amat = np.random.normal(size=(40,40))\n",
    "A = Amat.copy()\n",
    "A = tosparse(A)\n",
    "A = MatrixLinearOperator(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b449e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "Apinv = BandedCholeskyPinvOperator(A, delta=1e-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9d2c331f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.030267318020561e-10"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = np.random.normal(size=Apinv.shape[1])\n",
    "np.linalg.norm( (Apinv @ u) - (np.linalg.pinv(Amat) @ u) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5e54a9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_adjoint(Apinv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ea190c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "Apinv = Apinv.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f6f58387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1.46050069e-09)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = cp.random.normal(size=Apinv.shape[1])\n",
    "cp.linalg.norm( (Apinv @ u) - (cp.asarray(np.linalg.pinv(Amat)) @ u) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0cdb89d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_adjoint(Apinv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4bb56841",
   "metadata": {},
   "outputs": [],
   "source": [
    "Amat = cp.random.normal(size=(40,40))\n",
    "A = Amat.copy()\n",
    "A = tosparse(A)\n",
    "A = MatrixLinearOperator(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3a4b4fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Apinv = BandedCholeskyPinvOperator(A, delta=1e-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c639ee28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1.42238999e-10)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = cp.random.normal(size=Apinv.shape[1])\n",
    "cp.linalg.norm( (Apinv @ u) - (cp.asarray(np.linalg.pinv(Amat)) @ u) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c4e1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06be4873",
   "metadata": {},
   "source": [
    "# QR Pseudoinverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7c4de5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cupy.linalg import qr as cp_qr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c9ed8932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import qr as sp_qr\n",
    "from cupy.linalg import qr as cp_qr\n",
    "from scipy.linalg import solve_triangular as sp_solve_triangular\n",
    "from cupyx.scipy.linalg import solve_triangular as cp_solve_triangular\n",
    "\n",
    "\n",
    "class QRPinvOperator(_CustomLinearOperator):\n",
    "    \"\"\"Takes a dense matrix A with full column rank, builds a linear operator representing the pseudo-inverse of A\n",
    "    using the QR method.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, A):\n",
    "\n",
    "        assert isinstance(A, MatrixLinearOperator), \"must give MatrixOperator as an input.\"\n",
    "\n",
    "        # Store original operator\n",
    "        self.original_op = A\n",
    "        k, n = A.shape\n",
    "        \n",
    "        # Device\n",
    "        device = A.device\n",
    "        \n",
    "        if device == \"cpu\":\n",
    "            \n",
    "            Q_fac, R_fac = sp_qr(A.A, mode=\"economic\")\n",
    "\n",
    "            # Build matvec and rmatvec\n",
    "            def _matvec(vec):\n",
    "                tmp = Q_fac.T @ vec\n",
    "                tmp = sp_solve_triangular(R_fac, tmp, lower=False)\n",
    "                return tmp\n",
    "\n",
    "            def _rmatvec(vec):\n",
    "                tmp = scipy_solve_triangular(R_fac.T, vec, lower=True)\n",
    "                tmp = Q_fac @ tmp\n",
    "                return tmp\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # economic is deprecated\n",
    "            Q_fac, R_fac = cp_qr(A.A, mode=\"reduced\")\n",
    "\n",
    "            # Build matvec and rmatvec\n",
    "            def _matvec(vec):\n",
    "                tmp = Q_fac.T @ vec\n",
    "                tmp = cp_solve_triangular(R_fac, tmp, lower=False)\n",
    "                return tmp\n",
    "\n",
    "            def _rmatvec(vec):\n",
    "                tmp = cp_solve_triangular(R_fac.T, vec, lower=True)\n",
    "                tmp = Q_fac @ tmp\n",
    "                return tmp\n",
    "\n",
    "        super().__init__( (n, k), _matvec, _rmatvec , device=device)\n",
    "        \n",
    "        \n",
    "    def to_gpu(self):\n",
    "        return QRPseudoInverseOperator(self.original_op.to_gpu())\n",
    "    \n",
    "    def to_cpu(self):\n",
    "        return QRPseudoInverseOperator(self.original_op.to_cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d6fee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e54abb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b96ce48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2719202621569003e-16"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wmat = np.random.normal(size=(30,3))\n",
    "W = MatrixLinearOperator(Wmat)\n",
    "Wpinv = QRPinvOperator(W)\n",
    "\n",
    "u = np.random.normal(size=Wpinv.shape[1])\n",
    "np.linalg.norm( (Wpinv @ u) - (np.linalg.pinv(Wmat) @ u) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3c05787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wpinv = Wpinv.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ee48697e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(6.35960131e-17)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = cp.random.normal(size=Wpinv.shape[1])\n",
    "cp.linalg.norm( (Wpinv @ u) - (cp.asarray(np.linalg.pinv(Wmat)) @ u) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb651a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d309076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ab9b19a",
   "metadata": {},
   "source": [
    "# CGPseudoinverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "443b1c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jlinops import cg as jlinops_cg\n",
    "from scipy.sparse.linalg import cg as scipy_cg\n",
    "from cupyx.scipy.sparse.linalg import cg as cupy_cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "36bc6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGPinvOperator(_CustomLinearOperator):\n",
    "    \"\"\"Returns a linear operator that approximately computes the pseudoinverse of a matrix A using \n",
    "    a conjugate gradient method.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, A, warmstart_prev=False, which=\"jlinops\", check=False, *args, **kwargs):\n",
    "\n",
    "        assert which in [\"jlinops\", \"scipy\"], \"Invalid choice for which!\"\n",
    "\n",
    "        # Store operator\n",
    "        self.original_op = A\n",
    "        self.A = A\n",
    "        \n",
    "        # Device\n",
    "        device = A.device\n",
    "        \n",
    "        # Shape\n",
    "        m, n = A.shape\n",
    "        shape = (n, m)\n",
    "    \n",
    "        # Setup\n",
    "        self.which = which\n",
    "        self.warmstart_prev = warmstart_prev\n",
    "        self.check = check\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "        self.in_shape = A.shape[0]\n",
    "        self.out_shape = A.shape[1]\n",
    "        \n",
    "        if device == \"cpu\":\n",
    "            self.prev_eval = np.zeros(self.out_shape)\n",
    "            self.prev_eval_t = np.zeros(self.in_shape)\n",
    "        else:\n",
    "            self.prev_eval = cp.zeros(self.out_shape)\n",
    "            self.prev_eval_t = cp.zeros(self.in_shape)\n",
    "            \n",
    "        self.warmstart_prev = warmstart_prev\n",
    "\n",
    "        # Build both operators we need\n",
    "        self.AtA = self.original_op.T @ self.original_op\n",
    "        self.AAt = self.original_op @ self.original_op.T\n",
    "        \n",
    "        \n",
    "        if device == \"cpu\":\n",
    "            \n",
    "            if self.which == \"jlinops\":\n",
    "                \n",
    "                def _matvec(x):\n",
    "                    solver_data = jlinops_cg(self.AtA, self.A.rmatvec(x), x0=self.prev_eval, *args, **kwargs)\n",
    "                    sol = solver_data[\"x\"]\n",
    "                    if self.check:\n",
    "                        assert solver_data[\"converged\"], \"CG algorithm did not converge\"\n",
    "                    \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval = sol.copy()\n",
    "                    \n",
    "                    return sol\n",
    "                \n",
    "                def _rmatvec(x):\n",
    "                    solver_data = jlinops_cg(self.AAt, self.A.matvec(x), x0=self.prev_eval_t, *args, **kwargs)\n",
    "                    sol = solver_data[\"x\"]\n",
    "                    if self.check:\n",
    "                        assert solver_data[\"converged\"], \"CG algorithm did not converge\"\n",
    "                        \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval_t = sol.copy()\n",
    "                        \n",
    "                    return sol\n",
    "        \n",
    "            elif self.which == \"scipy\":\n",
    "                \n",
    "                def _matvec(x):\n",
    "                    sol, converged = scipy_cg(self.AtA, self.A.rmatvec(x), x0=self.prev_eval, *args, **kwargs) \n",
    "                    if self.check:\n",
    "                        assert converged == 0, \"CG algorithm did not converge!\"\n",
    "                        \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval = sol.copy()\n",
    "                    \n",
    "                    return sol\n",
    "                \n",
    "                def _rmatvec(x):\n",
    "                    sol, converged = scipy_cg(self.AAt, self.A.matvec(x), x0=self.prev_eval_t, *args, **kwargs) \n",
    "                    if self.check:\n",
    "                        assert converged == 0, \"CG algorithm did not converge!\"\n",
    "                    \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval_t = sol.copy()\n",
    "                    \n",
    "                    return sol\n",
    "                \n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            \n",
    "            if self.which == \"jlinops\":\n",
    "                \n",
    "                def _matvec(x):\n",
    "                    solver_data = jlinops_cg(self.AtA, self.A.rmatvec(x), x0=self.prev_eval, *args, **kwargs)\n",
    "                    sol = solver_data[\"x\"]\n",
    "                    if self.check:\n",
    "                        assert solver_data[\"converged\"], \"CG algorithm did not converge\"\n",
    "                        \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval = sol.copy()\n",
    "                        \n",
    "                    return sol\n",
    "                \n",
    "                def _rmatvec(x):\n",
    "                    solver_data = jlinops_cg(self.AAt, self.A.matvec(x), x0=self.prev_eval_t, *args, **kwargs)\n",
    "                    sol = solver_data[\"x\"]\n",
    "                    if self.check:\n",
    "                        assert solver_data[\"converged\"], \"CG algorithm did not converge\"\n",
    "                    \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval_t = sol.copy()\n",
    "                    \n",
    "                    return sol\n",
    "        \n",
    "            elif self.which == \"scipy\":\n",
    "                \n",
    "                def _matvec(x):\n",
    "                    sol, converged = cupy_cg(self.AtA, self.A.rmatvec(x), x0=self.prev_eval, *args, **kwargs) \n",
    "                    if self.check:\n",
    "                        assert converged == 0, \"CG algorithm did not converge!\"\n",
    "                    \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval = sol.copy()\n",
    "                        \n",
    "                    return sol\n",
    "                \n",
    "                def _rmatvec(x):\n",
    "                    sol, converged = cupy_cg(self.AAt, self.A.matvec(x), x0=self.prev_eval_t, *args, **kwargs) \n",
    "                    if self.check:\n",
    "                        assert converged == 0, \"CG algorithm did not converge!\"\n",
    "                    \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval_t = sol.copy()\n",
    "                        \n",
    "                    return sol\n",
    "                \n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            \n",
    "            \n",
    "        super().__init__( shape, _matvec, _rmatvec, device=device, dtype=self.A.dtype)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def to_gpu(self):\n",
    "        return CGPinvOperator(self.A.to_gpu(), warmstart_prev=self.warmstart_prev, which=self.which, check=self.check, *self.args, **self.kwargs)\n",
    "    \n",
    "    def to_cpu(self):\n",
    "        return CGPinvOperator(self.A.to_cpu(), warmstart_prev=self.warmstart_prev, which=self.which, check=self.check, *self.args, **self.kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "845443f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGModPinvOperator(_CustomLinearOperator):\n",
    "    \"\"\"Returns a linear operator that approximately computes the pseudoinverse of a matrix A using \n",
    "    a conjugate gradient method. Modifed so that it only ever solves systems with A^T A. \n",
    "    \n",
    "    W: a LinearOperator representing a matrix with linearly independent columns that spans null(A).\n",
    "    Wpinv: a LinearOperator represening the pseudoinverse of W.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, A, W, Wpinv, warmstart_prev=False, which=\"jlinops\", check=False, *args, **kwargs):\n",
    "\n",
    "        assert which in [\"jlinops\", \"scipy\"], \"Invalid choice for which!\"\n",
    "\n",
    "        # Store operator\n",
    "        self.original_op = A\n",
    "        self.A = A\n",
    "        self.W = W\n",
    "        self.Wpinv = Wpinv\n",
    "        \n",
    "        # Device\n",
    "        device = A.device\n",
    "    \n",
    "        # Shape\n",
    "        m, n = A.shape\n",
    "        shape = (n, m)\n",
    "    \n",
    "        # Setup\n",
    "        self.which = which\n",
    "        self.warmstart_prev = warmstart_prev\n",
    "        self.check = check\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "        self.in_shape = A.shape[0]\n",
    "        self.out_shape = A.shape[1]\n",
    "        \n",
    "        if device == \"cpu\":\n",
    "            self.prev_eval = np.zeros(self.out_shape)\n",
    "            self.prev_eval_t = np.zeros(self.in_shape)\n",
    "        else:\n",
    "            self.prev_eval = cp.zeros(self.out_shape)\n",
    "            self.prev_eval_t = cp.zeros(self.in_shape)\n",
    "            \n",
    "        self.warmstart_prev = warmstart_prev\n",
    "\n",
    "        # Build both operators we need\n",
    "        self.AtA = self.original_op.T @ self.original_op\n",
    "        self.AAt = self.original_op @ self.original_op.T\n",
    "        \n",
    "        \n",
    "        if device == \"cpu\":\n",
    "            \n",
    "            if self.which == \"jlinops\":\n",
    "                \n",
    "                def _matvec(x):\n",
    "                    solver_data = jlinops_cg(self.AtA, self.A.rmatvec(x), x0=self.prev_eval, *args, **kwargs)\n",
    "                    sol = solver_data[\"x\"]\n",
    "                    if self.check:\n",
    "                        assert solver_data[\"converged\"], \"CG algorithm did not converge\"\n",
    "                    \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval = sol.copy()\n",
    "                    \n",
    "                    return sol\n",
    "                \n",
    "                def _rmatvec(x):\n",
    "                    \n",
    "                    # Project x onto range(A^T A) = range(A^T).\n",
    "                    x = x - (W @ (Wpinv @ x))\n",
    "                    \n",
    "                    solver_data = jlinops_cg(self.AtA, x, x0=self.prev_eval_t, *args, **kwargs)\n",
    "                    sol = solver_data[\"x\"]\n",
    "                    if self.check:\n",
    "                        assert solver_data[\"converged\"], \"CG algorithm did not converge\"\n",
    "                        \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval_t = sol.copy()\n",
    "                        \n",
    "                    return self.A @ sol\n",
    "        \n",
    "            elif self.which == \"scipy\":\n",
    "                \n",
    "                def _matvec(x):\n",
    "                    sol, converged = scipy_cg(self.AtA, self.A.rmatvec(x), x0=self.prev_eval, *args, **kwargs) \n",
    "                    if self.check:\n",
    "                        assert converged == 0, \"CG algorithm did not converge!\"\n",
    "                        \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval = sol.copy()\n",
    "                    \n",
    "                    return sol\n",
    "                \n",
    "                def _rmatvec(x):\n",
    "                    \n",
    "                    # Project x onto range(A^T A) = range(A^T).\n",
    "                    x = x - (W @ (Wpinv @ x))\n",
    "                    \n",
    "                    sol, converged = scipy_cg(self.AtA, x, x0=self.prev_eval_t, *args, **kwargs) \n",
    "                    if self.check:\n",
    "                        assert converged == 0, \"CG algorithm did not converge!\"\n",
    "                    \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval_t = sol.copy()\n",
    "                    \n",
    "                    return self.A @ sol\n",
    "                \n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            \n",
    "            if self.which == \"jlinops\":\n",
    "                \n",
    "                def _matvec(x):\n",
    "                    solver_data = jlinops_cg(self.AtA, self.A.rmatvec(x), x0=self.prev_eval, *args, **kwargs)\n",
    "                    sol = solver_data[\"x\"]\n",
    "                    if self.check:\n",
    "                        assert solver_data[\"converged\"], \"CG algorithm did not converge\"\n",
    "                        \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval = sol.copy()\n",
    "                        \n",
    "                    return sol\n",
    "                \n",
    "                def _rmatvec(x):\n",
    "                    \n",
    "                    # Project x onto range(A^T A) = range(A^T).\n",
    "                    x = x - (W @ (Wpinv @ x))\n",
    "                    \n",
    "                    solver_data = jlinops_cg(self.AtA, x, x0=self.prev_eval_t, *args, **kwargs)\n",
    "                    sol = solver_data[\"x\"]\n",
    "                    if self.check:\n",
    "                        assert solver_data[\"converged\"], \"CG algorithm did not converge\"\n",
    "                    \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval_t = sol.copy()\n",
    "                    \n",
    "                    return self.A @ sol\n",
    "        \n",
    "            elif self.which == \"scipy\":\n",
    "                \n",
    "                def _matvec(x):\n",
    "                    sol, converged = cupy_cg(self.AtA, self.A.rmatvec(x), x0=self.prev_eval, *args, **kwargs) \n",
    "                    if self.check:\n",
    "                        assert converged == 0, \"CG algorithm did not converge!\"\n",
    "                    \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval = sol.copy()\n",
    "                        \n",
    "                    return sol\n",
    "                \n",
    "                def _rmatvec(x):\n",
    "                    \n",
    "                    # Project x onto range(A^T A) = range(A^T).\n",
    "                    x = x - (W @ (Wpinv @ x))\n",
    "                    \n",
    "                    sol, converged = cupy_cg(self.AtA, x, x0=self.prev_eval_t, *args, **kwargs) \n",
    "                    if self.check:\n",
    "                        assert converged == 0, \"CG algorithm did not converge!\"\n",
    "                    \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval_t = sol.copy()\n",
    "                        \n",
    "                    return self.A @ sol\n",
    "                \n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            \n",
    "            \n",
    "        super().__init__( shape, _matvec, _rmatvec, device=device, dtype=self.A.dtype)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def to_gpu(self):\n",
    "        return CGModPinvOperator(self.A.to_gpu(), self.W.to_gpu(), self.Wpinv.to_gpu(), warmstart_prev=self.warmstart_prev, which=self.which, check=self.check, *self.args, **self.kwargs)\n",
    "    \n",
    "    def to_cpu(self):\n",
    "        return CGPModinvOperator(self.A.to_cpu(), self.W.to_cpu(), self.Wpinv.to_cpu(), warmstart_prev=self.warmstart_prev, which=self.which, check=self.check, *self.args, **self.kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "98c1b052",
   "metadata": {},
   "outputs": [],
   "source": [
    "Amat = np.random.normal(size=(60,40))\n",
    "Amat[:,-1] = Amat[:,-2]\n",
    "Amat = Amat.T @ Amat\n",
    "A = Amat.copy()\n",
    "A = MatrixLinearOperator(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "0824727c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Apinv = CGPinvOperator(A, tol=1e-9, which=\"scipy\")\n",
    "check_adjoint(Apinv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "7c754219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0319538686917293e-10"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = np.random.normal(size=Apinv.shape[1])\n",
    "np.linalg.norm( (Apinv @ u) - (np.linalg.pinv(Amat) @ u) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "5c3a5866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.396343545536628e-11"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = np.random.normal(size=Apinv.shape[0])\n",
    "np.linalg.norm( (Apinv.T @ u) - (np.linalg.pinv(Amat).T @ u) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "0ebc3813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Apinv = Apinv.to_gpu()\n",
    "check_adjoint(Apinv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "46505c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(9.11456091e-11)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = cp.random.normal(size=Apinv.shape[1])\n",
    "cp.linalg.norm( (Apinv @ u) - (cp.asarray(np.linalg.pinv(Amat)) @ u) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "fbf7c378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(6.31010465e-11)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = cp.random.normal(size=Apinv.shape[0])\n",
    "cp.linalg.norm( (Apinv.T @ u) - (cp.asarray(np.linalg.pinv(Amat).T) @ u) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eed1985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f419bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "52a7c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Amat = np.random.normal(size=(60,40))\n",
    "Amat[:,-1] = Amat[:,-2]\n",
    "Amat = Amat.T @ Amat\n",
    "A = Amat.copy()\n",
    "A = MatrixLinearOperator(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "03552aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = null_space(Amat)\n",
    "W = MatrixLinearOperator(W)\n",
    "Wpinv = QRPinvOperator(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "830b893b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Apinv = CGModPinvOperator(A, W, Wpinv, tol=1e-9, which=\"scipy\")\n",
    "check_adjoint(Apinv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "875958a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2282461368355753e-11"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = np.random.normal(size=Apinv.shape[1])\n",
    "np.linalg.norm( (Apinv @ u) - (np.linalg.pinv(Amat) @ u) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "7455679e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2379468240116435e-11"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = np.random.normal(size=Apinv.shape[0])\n",
    "np.linalg.norm( (Apinv.T @ u) - (np.linalg.pinv(Amat).T @ u) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "91783aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Apinv = Apinv.to_gpu()\n",
    "check_adjoint(Apinv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "db527d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(6.81249161e-12)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = cp.random.normal(size=Apinv.shape[1])\n",
    "cp.linalg.norm( (Apinv @ u) - (cp.asarray(np.linalg.pinv(Amat)) @ u) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "5e9f5070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2.82265432e-11)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = cp.random.normal(size=Apinv.shape[0])\n",
    "cp.linalg.norm( (Apinv.T @ u) - (cp.asarray(np.linalg.pinv(Amat).T) @ u) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de5be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c33bdf1a",
   "metadata": {},
   "source": [
    "# Preconditioned CGpinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "eb8b15e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGPreconditionedPinvOperator(_CustomLinearOperator):\n",
    "    \"\"\"Returns a linear operator that approximately computes the pseudoinverse of a matrix A using \n",
    "    a conjugate gradient method. Modifed so that it only ever solves systems with A^T A. \n",
    "    \n",
    "    W: a LinearOperator representing a matrix with linearly independent columns that spans null(A).\n",
    "    Wpinv: a LinearOperator represening the pseudoinverse of W.\n",
    "    Lpinv: \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, A, W, Wpinv, Lpinv, warmstart_prev=True, check=False, which=\"jlinops\", *args, **kwargs):\n",
    "\n",
    "        assert which in [\"jlinops\", \"scipy\"], \"Invalid choice for which!\"\n",
    "\n",
    "        # Device\n",
    "        device = A.device\n",
    "        \n",
    "        # Store operator\n",
    "        self.A = A\n",
    "        self.W = W\n",
    "        self.Wpinv = Wpinv\n",
    "        self.Lpinv = Lpinv\n",
    "        self.Ltpinv = Lpinv.T\n",
    "        \n",
    "        # Shape\n",
    "        m, n = A.shape\n",
    "        shape = (n, m)\n",
    "\n",
    "        # Setup\n",
    "        self.which = which\n",
    "        self.check = check\n",
    "        self.warmstart_prev = warmstart_prev\n",
    "        self.in_shape = self.A.shape[0]\n",
    "        self.out_shape = self.A.shape[1]\n",
    "        \n",
    "        if device == \"cpu\":\n",
    "            self.prev_eval = np.zeros(self.out_shape)\n",
    "            self.prev_eval_t = np.zeros(self.out_shape)\n",
    "        else:\n",
    "            self.prev_eval = cp.zeros(self.out_shape)\n",
    "            self.prev_eval_t = cp.zeros(self.out_shape)\n",
    "\n",
    "        # Build both operators we need\n",
    "        self.AtA = self.A.T @ self.A\n",
    "        self.Q = self.Lpinv @ self.AtA @ self.Ltpinv\n",
    "\n",
    "        \n",
    "        if device == \"cpu\":\n",
    "            \n",
    "            if self.which == \"jlinops\":\n",
    "                \n",
    "                def _matvec(x):\n",
    "                    solver_data = jlinops_cg(self.Q, self.Lpinv @ (self.A.rmatvec(x)), x0=self.prev_eval, *args, **kwargs)\n",
    "                    sol = solver_data[\"x\"]\n",
    "                    if self.check:\n",
    "                        assert solver_data[\"converged\"], \"CG algorithm did not converge\"\n",
    "                    \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval = sol.copy()\n",
    "                    \n",
    "                    return self.Ltpinv @ sol\n",
    "                \n",
    "                def _rmatvec(x):\n",
    "                    \n",
    "                    # Project x onto range(A^T A) = range(A^T).\n",
    "                    x = x - (W @ (Wpinv @ x))\n",
    "                    \n",
    "                    solver_data = jlinops_cg(self.Q, self.Lpinv @ x, x0=self.prev_eval_t, *args, **kwargs)\n",
    "                    sol = solver_data[\"x\"]\n",
    "                    if self.check:\n",
    "                        assert solver_data[\"converged\"], \"CG algorithm did not converge\"\n",
    "                        \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval_t = sol.copy()\n",
    "                        \n",
    "                    return self.A @ (self.Ltpinv @ sol)\n",
    "        \n",
    "            elif self.which == \"scipy\":\n",
    "                \n",
    "                def _matvec(x):\n",
    "                    sol, converged = scipy_cg(self.Q, self.Lpinv @ (self.A.rmatvec(x)), x0=self.prev_eval, *args, **kwargs) \n",
    "                    if self.check:\n",
    "                        assert converged == 0, \"CG algorithm did not converge!\"\n",
    "                    \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval = sol.copy()\n",
    "                    \n",
    "                    return self.Ltpinv @ sol\n",
    "                \n",
    "                def _rmatvec(x):\n",
    "                    \n",
    "                    # Project x onto range(A^T A) = range(A^T).\n",
    "                    x = x - (W @ (Wpinv @ x))\n",
    "                    \n",
    "                    sol, converged = scipy_cg(self.Q, self.Lpinv @ x, x0=self.prev_eval_t, *args, **kwargs) \n",
    "                    if self.check:\n",
    "                        assert converged == 0, \"CG algorithm did not converge!\"\n",
    "                    \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval_t = sol.copy()\n",
    "                    \n",
    "                    return self.A @ (self.Ltpinv @ sol)\n",
    "                \n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            \n",
    "            if self.which == \"jlinops\":\n",
    "                \n",
    "                def _matvec(x):\n",
    "                    solver_data = jlinops_cg(self.Q, self.Lpinv @ (self.A.rmatvec(x)), x0=self.prev_eval, *args, **kwargs)\n",
    "                    sol = solver_data[\"x\"]\n",
    "                    if self.check:\n",
    "                        assert solver_data[\"converged\"], \"CG algorithm did not converge\"\n",
    "                        \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval = sol.copy()\n",
    "                        \n",
    "                    return self.Ltpinv @ sol\n",
    "                \n",
    "                def _rmatvec(x):\n",
    "                    \n",
    "                    # Project x onto range(A^T A) = range(A^T).\n",
    "                    x = x - (W @ (Wpinv @ x))\n",
    "                    \n",
    "                    solver_data = jlinops_cg(self.Q, self.Lpinv @ x, x0=self.prev_eval_t, *args, **kwargs)\n",
    "                    sol = solver_data[\"x\"]\n",
    "                    if self.check:\n",
    "                        assert solver_data[\"converged\"], \"CG algorithm did not converge\"\n",
    "                    \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval_t = sol.copy()\n",
    "                    \n",
    "                    return self.A @ (self.Ltpinv @ sol)\n",
    "        \n",
    "            elif self.which == \"scipy\":\n",
    "                \n",
    "                def _matvec(x):\n",
    "                    sol, converged = cupy_cg(self.Q, self.Lpinv @ (self.A.rmatvec(x)), x0=self.prev_eval, *args, **kwargs)\n",
    "                    if self.check:\n",
    "                        assert converged == 0, \"CG algorithm did not converge!\"\n",
    "                    \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval = sol.copy()\n",
    "                        \n",
    "                    return self.Ltpinv @ sol\n",
    "                \n",
    "                def _rmatvec(x):\n",
    "                    \n",
    "                    # Project x onto range(A^T A) = range(A^T).\n",
    "                    x = x - (W @ (Wpinv @ x))\n",
    "                    \n",
    "                    sol, converged = cupy_cg(self.Q, self.Lpinv @ x, x0=self.prev_eval_t, *args, **kwargs) \n",
    "                    if self.check:\n",
    "                        assert converged == 0, \"CG algorithm did not converge!\"\n",
    "                    \n",
    "                    if self.warmstart_prev:\n",
    "                        self.prev_eval_t = sol.copy()\n",
    "                        \n",
    "                    return self.A @ (self.Ltpinv @ sol)\n",
    "                \n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "        \n",
    "        \n",
    "        super().__init__( shape, _matvec, _rmatvec, dtype=np.float64, device=device)\n",
    "        \n",
    "        \n",
    "    def to_gpu(self):\n",
    "        return CGPreconditionedPinvOperator(self.A.to_gpu(), self.W.to_gpu(), self.Wpinv.to_gpu(), self.Lpinv.to_gpu(), warmstart_prev=self.warmstart_prev, which=self.which, check=self.check, *self.args, **self.kwargs)\n",
    "    \n",
    "        \n",
    "    def to_cpu(self):\n",
    "        return CGPreconditionedPinvOperator(self.A.to_cpu(), self.W.to_cpu(), self.Wpinv.to_cpu(), self.Lpinv.to_cpu(), warmstart_prev=self.warmstart_prev, which=self.which, check=self.check, *self.args, **self.kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "71203c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CGWeightedNeumann2DPinvOperator(_CustomLinearOperator):\n",
    "    \"\"\"Represents the pseudoinverse (R_w)^\\dagger of a linear operator R_w = D_w R, where\n",
    "    D_w is a diagonal matrix of weights and R is a DiscreteGradientNeumann2D operator.\n",
    "    Here matvecs/rmatvecs are applied approximately using a preconditioned conjugate\n",
    "    gradient method, where the preconditioner is based on the operator with identity weights. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, grid_shape, weights, warmstart_prev=True, check=False, which=\"jlinops\", *args, **kwargs):\n",
    "\n",
    "        assert 2*math.prod(grid_shape) == len(weights), \"Weights incompatible!\"\n",
    "        self.weights = weights\n",
    "        self.grid_shape = grid_shape\n",
    "        self.warmstart_prev = warmstart_prev\n",
    "        self.check = check\n",
    "        self.which = which\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "        # Figure out device\n",
    "        device = get_device(weights)\n",
    "\n",
    "        # Build R_w\n",
    "        self.R = Neumann2D(grid_shape, device=device)\n",
    "        self.Dw = DiagonalOperator(weights)\n",
    "        self.Rw = self.Dw @ self.R\n",
    "\n",
    "        # Get Rpinv (with identity weights)\n",
    "        self.Rpinv = dct_sqrt_pinv(self.R.T @ self.R, grid_shape)\n",
    "\n",
    "        # Take care of W (columns span the kernel of R)\n",
    "        if device == \"cpu\":\n",
    "            W = np.ones((self.R.shape[1],1))\n",
    "        else:\n",
    "            W = cp.ones((self.R.shape[1],1))\n",
    "            \n",
    "        self.W = MatrixLinearOperator(W)\n",
    "        self.Wpinv = QRPseudoInverseOperator(self.W)\n",
    "\n",
    "        # Make Rwpinv\n",
    "        self.Rwpinv = CGPreconditionedPinvOperator(self.Rw, self.W, self.Wpinv, self.Rpinv, warmstart_prev=warmstart_prev, check=check, which=which, *args, **kwargs)\n",
    "\n",
    "        def _matvec(x):\n",
    "            return self.Rwpinv @ x\n",
    "\n",
    "        def _rmatvec(x):\n",
    "            return self.Rwpinv.T @ x\n",
    "\n",
    "        super().__init__( self.Rwpinv.shape, _matvec, _rmatvec, dtype=np.float64, device=device)\n",
    "        \n",
    "\n",
    "    def to_gpu(self):\n",
    "        return CGWeightedNeumann2DPinvOperator(self.grid_shape, cp.asarray(self.weights), warmstart_prev=self.warmstart_prev, check=self.check, which=self.which, *self.args, **self.kwargs)\n",
    "    \n",
    "    def to_cpu(self):\n",
    "        return CGWeightedNeumann2DPinvOperator(self.grid_shape, cp.numpy(self.weights), warmstart_prev=self.warmstart_prev, check=self.check, which=self.which, *self.args, **self.kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "2ccfeda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jlinops import get_device, Neumann2D, DiagonalOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "284ae924",
   "metadata": {},
   "outputs": [],
   "source": [
    "M, N = 1000, 1000\n",
    "weights = np.random.uniform(low=1e-1, high=1e1, size=2*M*N)\n",
    "grid_shape = (M,N)\n",
    "A = CGWeightedNeumann2DPinvOperator(grid_shape, weights, which=\"scipy\", tol=1e-7)\n",
    "#A = CGWeightedNeumann2DPinvOperator(grid_shape, weights, which=\"jlinops\", eps=1e-7)\n",
    "#check_adjoint(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "428eefa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.2 s  823 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "u = np.random.normal(size=A.shape[1])\n",
    "_ = A @ u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "8d4b873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "952c3aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_adjoint(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "db635849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15 s  11.6 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "u = cp.random.normal(size=A.shape[1])\n",
    "_ = A @ u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "9a60c5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425 ms  15.8 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "u = cp.random.normal(size=A.shape[1])\n",
    "_ = A @ u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75626895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a790d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "7c6c5800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101.6470588235294"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "43200/425"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "c41d977e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102.74509803921569"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "26200/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "033223bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.5462962962963"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9190/216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b51445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b186377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "19a3f7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20068115, 0.20499076, 0.18600398, ..., 0.18497829, 0.37659145,\n",
       "       0.03446162])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = np.random.normal(size=A.shape[1])\n",
    "A @ u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "53586157",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "3ad772bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35298313, 0.11578183, 0.15125623, ..., 0.19635416, 0.34345851,\n",
       "       0.82423415])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = cp.random.normal(size=A.shape[1])\n",
    "A @ u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "54bf1104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_adjoint(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f85eec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a43ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7142a22b",
   "metadata": {},
   "source": [
    "# Old version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f969bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f3c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa460b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed75bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8b0933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f8fc7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeac616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf766fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648760dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jlinops",
   "language": "python",
   "name": "jlinops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
